"""
üß© utils.py ‚Äì Funciones auxiliares para el an√°lisis estructural y sem√°ntico de documentos PDF

Este m√≥dulo cumple el rol de "gen auxiliar" dentro del pipeline OpenPages.
Proporciona funciones reutilizables que permiten:
- Evaluar la complejidad visual de un PDF (bloques o escaneado)
- Detectar posibles f√≥rmulas u objetos no textuales
- Normalizar texto para matching sem√°ntico
- Calcular un hash √∫nico (MD5) que act√∫a como identificador gen√©tico del documento

Todas las funciones est√°n dise√±adas para ser:
‚úîÔ∏è Independientes
‚úîÔ∏è Trazables
‚úîÔ∏è Reutilizables
‚úîÔ∏è Seguras ante errores comunes
"""

from unidecode import unidecode
import fitz  # PyMuPDF
import re
import hashlib


def es_pdf_complejo(ruta_pdf: str, max_paginas: int = 3, umbral: int = 8) -> bool:
    """
    Eval√∫a si un PDF es "complejo" en su estructura visual.

    Criterios:
    - Muchos bloques detectados (posible layout complicado: columnas, tablas)
    - Ning√∫n bloque visible (posible imagen o escaneado)

    Args:
        ruta_pdf: Ruta local del archivo PDF.
        max_paginas: N√∫mero de p√°ginas a analizar (default: 3).
        umbral: Cantidad promedio de bloques para considerarlo complejo.

    Returns:
        True si el PDF es complejo, False si es "simple".
    """
    try:
        doc = fitz.open(ruta_pdf)
    except Exception as e:
        print(f"‚ùå Error abriendo PDF: {e}")
        return True  # Por defecto, tratamos como complejo si no se puede abrir

    paginas = min(len(doc), max_paginas)
    total_bloques = 0

    for i in range(paginas):
        bloques = doc[i].get_text("blocks")
        total_bloques += len(bloques)

    doc.close()

    if total_bloques == 0:
        return True  # Escaneado o sin texto detectable

    promedio = total_bloques / paginas
    return promedio > umbral


def contiene_formula(texto: str) -> bool:
    """
    Detecta si un bloque de texto contiene f√≥rmulas u objetos sospechosos,
    usando la proporci√≥n de s√≠mbolos no alfab√©ticos como indicador.

    Tambi√©n filtra textos demasiado cortos.

    Args:
        texto: Fragmento de texto (p√°rrafo o l√≠nea).

    Returns:
        True si parece contener f√≥rmula o es sospechoso, False si es texto normal.
    """
    if not texto or len(texto.strip()) < 10:
        return True

    simbolos = re.findall(r"[^a-zA-Z0-9\s]", texto)
    proporcion = len(simbolos) / len(texto)

    return proporcion > 0.3


def normalizar_texto(texto: str) -> str:
    """
    Limpieza sem√°ntica del texto para b√∫squedas y comparaci√≥n.

    Acciones:
    - Convierte a min√∫sculas
    - Elimina acentos y caracteres especiales (via unidecode)

    Args:
        texto: Cualquier string

    Returns:
        Texto normalizado, listo para matching sem√°ntico
    """
    return unidecode(texto.lower())


def calcular_hash_md5(path_pdf: str) -> str:
    """
    Calcula el hash MD5 √∫nico de un archivo PDF.

    Usado para:
    - Trazabilidad de documentos
    - Nombrado de logs
    - Identificaci√≥n gen√©tica en IA-ready exports

    Args:
        path_pdf: Ruta absoluta al archivo

    Returns:
        Cadena hexadecimal (32 caracteres)
    """
    try:
        with open(path_pdf, 'rb') as f:
            contenido = f.read()
            return hashlib.md5(contenido).hexdigest()
    except FileNotFoundError:
        raise FileNotFoundError(f"‚ö†Ô∏è Archivo no encontrado para hashing: {path_pdf}")
