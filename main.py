# main.py

"""
Script principal del Dewey Pipeline ðŸ§ ðŸ“˜

Este script recorre todos los archivos PDF en /input, ejecuta el pipeline completo (extracciÃ³n, limpieza, clasificaciÃ³n, exportaciÃ³n)
y registra eventos importantes mediante el mÃ³dulo logger.

ðŸ“˜ Para mÃ¡s informaciÃ³n sobre el sistema de logging:
Ver README.logger.md
"""

import os
from pathlib import Path

from src.parser import extract_text
from src.cleaner import limpiar_texto_completo
from src.classifier import clasificar_documento
from src.exporter import exportar_archivos
from src.logger import log_evento  # <- Logger central visual + persistente

INPUT_DIR = "input"
OUTPUT_DIR = "output"

def main():
    print("ðŸš€ Iniciando Dewey Pipeline...")

    # âœ… ValidaciÃ³n inicial de carpetas
    if not Path(INPUT_DIR).exists():
        raise FileNotFoundError(f"El directorio de entrada '{INPUT_DIR}' no existe.")
    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)

    archivos_pdf = list(Path(INPUT_DIR).rglob("*.pdf"))
    if not archivos_pdf:
        print("âš ï¸ No se encontraron archivos PDF en la carpeta 'input/'")
        return

    print(f"ðŸ” Se encontraron {len(archivos_pdf)} archivos para procesar.")

    resumen = {"procesados": 0, "omitidos": 0, "errores": 0}

    for archivo in archivos_pdf:
        ruta = str(archivo)
        tipo = Path(archivo).parent.name  # Carpeta como tipo

        # ðŸ” Verificar accesibilidad fÃ­sica del archivo
        try:
            with open(ruta, "rb") as f:
                f.read(4)
        except Exception:
            log_evento("archivo_inaccesible", archivo=ruta, nivel="ERROR")
            resumen["errores"] += 1
            continue

        try:
            # 1ï¸âƒ£ Registro de inicio
            log_evento("procesar", archivo=ruta)

            # 2ï¸âƒ£ ExtracciÃ³n de texto
            texto_crudo = extract_text(ruta)

            # 3ï¸âƒ£ Limpieza
            texto_limpio = limpiar_texto_completo(texto_crudo, modo_md=True)

            if len(texto_limpio.strip()) < 300:
                log_evento("warning_texto_corto", archivo=ruta, nivel="WARNING")
                resumen["omitidos"] += 1
                continue

            # 4ï¸âƒ£ ClasificaciÃ³n
            resultado = clasificar_documento(texto_limpio)
            categoria = resultado.get("categoria")
            dewey = resultado.get("dewey")
            titulo = resultado.get("titulo")
            autor = resultado.get("autor")

            # 5ï¸âƒ£ ValidaciÃ³n de metadatos
            if not all([titulo, autor, categoria, dewey]):
                log_evento("warning_meta", archivo=ruta, nivel="WARNING")
                resumen["omitidos"] += 1
                continue

            # 6ï¸âƒ£ ExportaciÃ³n
            exportar_archivos(tipo, titulo, texto_limpio, categoria, dewey, autor)

            # 7ï¸âƒ£ Logs estructurados
            log_evento("clasificado", archivo=ruta, categoria=categoria, dewey=dewey)
            log_evento("export_ok", archivo=ruta, categoria=categoria, dewey=dewey)
            resumen["procesados"] += 1

        except Exception as e:
            log_evento("error_parse", archivo=ruta, nivel="ERROR")
            print(f"âŒ Error procesando {ruta}: {e}")
            resumen["errores"] += 1

    # ðŸ”š Informe final
    print(f"""
ðŸ”š Resumen del Pipeline:
âœ”ï¸ Procesados: {resumen['procesados']}
âš ï¸ Omitidos: {resumen['omitidos']}
âŒ Errores: {resumen['errores']}
""")

if __name__ == "__main__":
    main()
