{
  "title": "-src_enhancer.py",
  "text": "## [[Tags]]\n-src_enhancer.py [[--- Codigo]] [[--üß¨ src/]]\n\n```python\nimport json\nimport re\nimport unicodedata\nfrom pathlib import Path\nfrom typing import Callable, Tuple, Dict, List\n\nfrom src.enhancer_utils import acumular_stats, aplicar_diccionario\n\n__all__ = [\n    'reemplazar_cid_ascii',\n    'reparar_encoding',\n    'normalizar_unicode',\n    'reparar_palabras_partidas',\n    'reparar_cid',\n    'reparar_ocr_simbolos',\n    'marcar_fragmentos_dudosos',\n    'pipeline_hooked_enhancer',\n    'enriquecer_texto',\n    'acumular_stats'\n]\n\n# === Funciones de reparaci√≥n sem√°ntica ===\n\ndef reemplazar_cid_ascii(texto: str) -> Tuple[str, Dict[str, int]]:\n    \"\"\"\n    Elimina etiquetas 'cid:123' y cuenta cu√°ntas sustituciones realiz√≥.\n    \"\"\"\n    matches = re.findall(r'cid:\\d+', texto)\n    nuevo_texto = re.sub(r'cid:\\d+', '', texto)\n    return nuevo_texto, {'reemplazos_cid_ascii': len(matches)}\n\ndef reparar_encoding(texto: str) -> Tuple[str, Dict[str, int]]:\n    \"\"\"\n    Corrige errores comunes de encoding (mojibake) en el texto.\n    \"\"\"\n    mapping = {\n        '√É¬°': '√°', '√É¬©': '√©', '√É¬≠': '√≠', '√É¬≥': '√≥', '√É¬∫': '√∫',\n        '√É¬±': '√±', '√É‚Äò': '√ë'\n    }\n    count = 0\n    nuevo = texto\n    for mal, bien in mapping.items():\n        ocurrencias = nuevo.count(mal)\n        if ocurrencias:\n            nuevo = nuevo.replace(mal, bien)\n            count += ocurrencias\n    return nuevo, {'reparaciones_encoding': count}\n\ndef normalizar_unicode(texto: str) -> Tuple[str, Dict[str, int]]:\n    \"\"\"\n    Normaliza la forma Unicode a NFC para asegurar combinaci√≥n de caracteres.\n    \"\"\"\n    return unicodedata.normalize('NFC', texto), {}\n\ndef reparar_palabras_partidas(texto: str) -> Tuple[str, Dict[str, int]]:\n    \"\"\"\n    Une palabras partidas al final de l√≠nea: 'pro-\\nducto' ‚Üí 'producto'.\n    \"\"\"\n    pattern = r'-\\s*\\n\\s*'\n    ocurrencias = len(re.findall(pattern, texto))\n    nuevo = re.sub(pattern, '', texto)\n    return nuevo, {'palabras_reparadas': ocurrencias}\n\ndef reparar_cid(texto: str) -> Tuple[str, Dict[str, int]]:\n    \"\"\"\n    Elimina patrones 'cid(123)' y cuenta las sustituciones.\n    \"\"\"\n    matches = re.findall(r'cid\\(\\d+\\)', texto)\n    nuevo = re.sub(r'cid\\(\\d+\\)', '', texto)\n    return nuevo, {'reemplazos_cid': len(matches)}\n\ndef reparar_ocr_simbolos(texto: str) -> Tuple[str, Dict[str, int]]:\n    \"\"\"\n    Sustituye ligaduras y s√≠mbolos OCR por caracteres ASCII est√°ndar:\n    'Ô¨Å' ‚Üí 'fi', 'Ô¨Ç' ‚Üí 'fl', '∆ü' ‚Üí 'O'.\n    \"\"\"\n    mapping = {'Ô¨Å': 'fi', 'Ô¨Ç': 'fl', '∆ü': 'O'}\n    count = 0\n    nuevo = texto\n    for mal, bien in mapping.items():\n        ocurrencias = nuevo.count(mal)\n        if ocurrencias:\n            nuevo = nuevo.replace(mal, bien)\n            count += ocurrencias\n    return nuevo, {'reparados_ocr_simbolos': count}\n\ndef marcar_fragmentos_dudosos(texto: str) -> Tuple[str, Dict[str, int]]:\n    \"\"\"\n    Marca fragmentos dudosos sin alterar el contenido,\n    a√±adiendo etiquetas para an√°lisis posterior (no-op por ahora).\n    \"\"\"\n    return texto, {}\n\n# === Pipeline adaptativo ===\n\ndef pipeline_hooked_enhancer(\n    texto: str,\n    config: Dict[str, any]\n) -> Tuple[str, Dict[str, float]]:\n    \"\"\"\n    üß¨ Enhancer adaptativo con hooks inteligentes.\n\n    Aplica funciones de reparaci√≥n sem√°ntica en orden definido y de forma adaptativa:\n    - Mide el impacto de cada paso (cu√°ntas correcciones aplic√≥).\n    - Reintenta los que superan cierto umbral de ganancia.\n    - Carga un diccionario OCR externo si est√° disponible.\n\n    Args:\n        texto: texto original a mejorar.\n        config: diccionario con:\n            pasos: lista de funciones que devuelven (texto, stats).\n            retry_umbral: umbral m√≠nimo de impacto para reintentar.\n            max_intentos: m√°ximo de repeticiones por funci√≥n.\n            ocr_dict_path: ruta opcional al archivo ocr_dict.json.\n\n    Returns:\n        texto corregido y estad√≠sticas acumuladas.\n    \"\"\"\n    pasos: List[Callable] = config.get('pasos', [])\n    retry_umbral: float = config.get('retry_umbral', 5)\n    max_intentos: int = config.get('max_intentos', 2)\n    stats_global: Dict[str, float] = {}\n    intentos: Dict[str, int] = {func.__name__: 0 for func in pasos}\n\n    # Cargar diccionario OCR si existe\n    dict_path = config.get('ocr_dict_path')\n    if dict_path and Path(dict_path).exists():\n        diccionario = json.loads(Path(dict_path).read_text(encoding='utf-8'))\n        pasos.insert(0, lambda t: aplicar_diccionario(t, diccionario))\n        intentos['<ocr_dict>'] = 0\n\n    # Loop adaptativo\n    cambios = True\n    texto_actual = texto\n    while cambios:\n        cambios = False\n        for func in pasos:\n            nombre = getattr(func, '__name__', '<ocr_dict>')\n            if intentos.get(nombre, 0) >= max_intentos:\n                continue\n\n            texto_nuevo, stats = func(texto_actual)\n            impacto = sum(v for v in stats.values() if isinstance(v, (int, float)))\n            if impacto >= retry_umbral:\n                cambios = True\n                intentos[nombre] += 1\n                texto_actual = texto_nuevo\n                stats_global = acumular_stats(stats_global, stats)\n\n    return texto_actual, stats_global\n\n# === Interfaz simple para main.py ===\n\ndef enriquecer_texto(\n    texto: str,\n    archivo: str = None,\n    debug: bool = False,\n    config: Dict[str, any] = None,\n    return_stats: bool = False  # ‚Üê ‚ö†Ô∏è NUEVO par√°metro opcional\n) -> str | Tuple[str, Dict[str, float]]:\n    \"\"\"\n    Funci√≥n de envoltura que expone un flujo de enriquecimiento sencillo,\n    aceptando par√°metros de debugging y configuraci√≥n opcional.\n\n    Args:\n        texto: Texto a enriquecer.\n        archivo: Ruta del PDF para debug o logging.\n        debug: Si True, muestra comparaci√≥n antes/despu√©s.\n        config: Diccionario con configuraci√≥n de pasos.\n        return_stats: Si True, retorna tambi√©n las estad√≠sticas.\n\n    Returns:\n        Solo texto enriquecido (por defecto),\n        o (texto, estad√≠sticas) si return_stats=True.\n    \"\"\"\n    default_steps = [\n        reemplazar_cid_ascii,\n        reparar_encoding,\n        normalizar_unicode,\n        reparar_palabras_partidas,\n        reparar_cid,\n        reparar_ocr_simbolos,\n        marcar_fragmentos_dudosos\n    ]\n    cfg = config or {}\n    cfg.setdefault('pasos', default_steps)\n\n    if debug and archivo:\n        print(f\"üîç [DEBUG] Pre-enriquecimiento ({archivo}): {texto[:200]}...\")\n\n    enriched, stats = pipeline_hooked_enhancer(texto, cfg)\n\n    if debug and archivo:\n        print(f\"üîç [DEBUG] Post-enriquecimiento ({archivo}): {enriched[:200]}...\")\n\n    return (enriched, stats) if return_stats else enriched\n\n```",
  "tags": "-src_enhancer.py [[--- Codigo]] [[--üß¨ src/]]",
  "type": "text/markdown",
  "created": "20250424205039106",
  "modified": "20250424205039106"
}